{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.folder import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from itertools import chain\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "BATCH = 2\n",
    "N_layers = 2 # LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     1,
     23
    ]
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Special class\n",
    "class MultiImageFolder(data.Dataset):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, len_seq=4):\n",
    "        classes, class_to_idx = find_classes(root)\n",
    "        imgs = make_dataset(root, class_to_idx, [\".jpg\",\".jpeg\",\".png\"])\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.len_seq =len_seq\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)//self.len_seq\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        img_l = []\n",
    "        target_l = []\n",
    "        for i in range(self.len_seq):\n",
    "            path, target = self.imgs[self.len_seq*index+i]\n",
    "            img = self.loader(path)\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "            if target_l and target != target_l[0]: break\n",
    "            img_l += [img]\n",
    "            target_l += [target]\n",
    "\n",
    "        return img_l, target\n",
    "\n",
    "# Datasets\n",
    "data_dir = './LittlePlaNet/data/cities/'\n",
    "image_datasets = {x: MultiImageFolder(os.path.join(data_dir, x),\n",
    "                                           data_transforms[x], len_seq=8)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH,\n",
    "                                           shuffle=True, num_workers=8, drop_last=True)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "m = torch.load(\"models/resnet50_trained\")\n",
    "\n",
    "num_ftrs = m.fc.in_features\n",
    "hidden = 80\n",
    "\n",
    "newtestds = MultiImageFolder(\"data/cities/\",data_transforms[\"test\"],len_seq=10)\n",
    "nt_dataloader = torch.utils.data.DataLoader(\n",
    "    newtestds,batch_size=BATCH, shuffle=True, num_workers=4, drop_last=True)\n",
    "class_names = newtestds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, num_ftrs, hidden, transf, num_layers=N_layers):\n",
    "        super(SeqModel, self).__init__()        \n",
    "        self.hidden = hidden\n",
    "        self.num_ftrs = num_ftrs\n",
    "        \n",
    "        self.emb = transf\n",
    "        self.L = nn.LSTM(num_ftrs, hidden, num_layers=num_layers, bidirectional = True).to(device)\n",
    "        self.h2la = nn.Linear(2*hidden, len(class_names)).to(device)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.h = (torch.zeros(2*N_layers, BATCH ,hidden).to(device),\n",
    "                  torch.zeros(2*N_layers,BATCH ,hidden).to(device))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        self.h = (torch.randn(self.num_layers, BATCH ,self.hidden).to(device),\n",
    "                  torch.randn(self.num_layers, BATCH ,self.hidden).to(device))\n",
    "        \n",
    "    def forward(self,inp):        \n",
    "        X = torch.stack([self.emb(inp[i].to(device)) for i in range(len(inp))]).squeeze() \n",
    "#         print(X.shape)\n",
    "        o,h = self.L(X.view(len(inp), -1 , self.num_ftrs),self.h)\n",
    "        res = nn.Softmax(dim=2)(self.h2la(self.drop(o)))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(nt_dataloader))\n",
    "y = y.to(device)\n",
    "sm = SeqModel(num_ftrs, hidden, nn.Sequential(*list(m.children())[:-1]).to(device))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(chain(sm.L.parameters(),sm.h2la.parameters()) , lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
    "# exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience = 4, factor = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "# inputs = torch.stack( inputs )\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs[:,1,:,:,:])\n",
    "\n",
    "# imshow(out, title=class_names[classes[1]])\n",
    "\n",
    "# Reset optimizer\n",
    "optimizer_ft = optim.Adam(chain(sm.L.parameters(),sm.h2la.parameters()) , lr=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
    "# exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, patience = 4, factor = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    hist = {\"train\":[], \"val\":[]}\n",
    "        \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':            \n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                model.emb.eval()\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                                            # last batch classes\n",
    "                    outputs = model(inputs)[len(inputs)-1,:,:]                                                \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    labels,\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * BATCH\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            hist[phase] += [[epoch_loss, epoch_acc]]\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/119\n",
      "----------\n",
      "train Loss: 2.3087 Acc: 0.1034\n",
      "val Loss: 2.2559 Acc: 0.2206\n",
      "\n",
      "Epoch 1/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1043\n",
      "val Loss: 2.2559 Acc: 0.2206\n",
      "\n",
      "Epoch 2/119\n",
      "----------\n",
      "train Loss: 2.3096 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 3/119\n",
      "----------\n",
      "train Loss: 2.3084 Acc: 0.1043\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 4/119\n",
      "----------\n",
      "train Loss: 2.3098 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 5/119\n",
      "----------\n",
      "train Loss: 2.3110 Acc: 0.1052\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 6/119\n",
      "----------\n",
      "train Loss: 2.3111 Acc: 0.1006\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 7/119\n",
      "----------\n",
      "train Loss: 2.3077 Acc: 0.1015\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 8/119\n",
      "----------\n",
      "train Loss: 2.3095 Acc: 0.1015\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 9/119\n",
      "----------\n",
      "train Loss: 2.3118 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 10/119\n",
      "----------\n",
      "train Loss: 2.3069 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 11/119\n",
      "----------\n",
      "train Loss: 2.3076 Acc: 0.1052\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 12/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1015\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 13/119\n",
      "----------\n",
      "train Loss: 2.3070 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 14/119\n",
      "----------\n",
      "train Loss: 2.3070 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 15/119\n",
      "----------\n",
      "train Loss: 2.3078 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 16/119\n",
      "----------\n",
      "train Loss: 2.3071 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 17/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 18/119\n",
      "----------\n",
      "train Loss: 2.3092 Acc: 0.1015\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 19/119\n",
      "----------\n",
      "train Loss: 2.3073 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 20/119\n",
      "----------\n",
      "train Loss: 2.3113 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 21/119\n",
      "----------\n",
      "train Loss: 2.3087 Acc: 0.1006\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 22/119\n",
      "----------\n",
      "train Loss: 2.3073 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 23/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1052\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 24/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 25/119\n",
      "----------\n",
      "train Loss: 2.3096 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 26/119\n",
      "----------\n",
      "train Loss: 2.3102 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 27/119\n",
      "----------\n",
      "train Loss: 2.3094 Acc: 0.1015\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 28/119\n",
      "----------\n",
      "train Loss: 2.3058 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 29/119\n",
      "----------\n",
      "train Loss: 2.3087 Acc: 0.1024\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 30/119\n",
      "----------\n",
      "train Loss: 2.3095 Acc: 0.1052\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 31/119\n",
      "----------\n",
      "train Loss: 2.3061 Acc: 0.1061\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 32/119\n",
      "----------\n",
      "train Loss: 2.3098 Acc: 0.1034\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 33/119\n",
      "----------\n",
      "train Loss: 2.3121 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 34/119\n",
      "----------\n",
      "train Loss: 2.3097 Acc: 0.1024\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 35/119\n",
      "----------\n",
      "train Loss: 2.3083 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 36/119\n",
      "----------\n",
      "train Loss: 2.3085 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 37/119\n",
      "----------\n",
      "train Loss: 2.3093 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 38/119\n",
      "----------\n",
      "train Loss: 2.3091 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 39/119\n",
      "----------\n",
      "train Loss: 2.3094 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 40/119\n",
      "----------\n",
      "train Loss: 2.3104 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 41/119\n",
      "----------\n",
      "train Loss: 2.3108 Acc: 0.1024\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 42/119\n",
      "----------\n",
      "train Loss: 2.3082 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 43/119\n",
      "----------\n",
      "train Loss: 2.3086 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 44/119\n",
      "----------\n",
      "train Loss: 2.3093 Acc: 0.1034\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 45/119\n",
      "----------\n",
      "train Loss: 2.3083 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 46/119\n",
      "----------\n",
      "train Loss: 2.3107 Acc: 0.1052\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 47/119\n",
      "----------\n",
      "train Loss: 2.3096 Acc: 0.1061\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 48/119\n",
      "----------\n",
      "train Loss: 2.3091 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 49/119\n",
      "----------\n",
      "train Loss: 2.3075 Acc: 0.1052\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 50/119\n",
      "----------\n",
      "train Loss: 2.3097 Acc: 0.1043\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 51/119\n",
      "----------\n",
      "train Loss: 2.3114 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 52/119\n",
      "----------\n",
      "train Loss: 2.3081 Acc: 0.1015\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 53/119\n",
      "----------\n",
      "train Loss: 2.3107 Acc: 0.1024\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 54/119\n",
      "----------\n",
      "train Loss: 2.3065 Acc: 0.1052\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 55/119\n",
      "----------\n",
      "train Loss: 2.3089 Acc: 0.1034\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 56/119\n",
      "----------\n",
      "train Loss: 2.3070 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 57/119\n",
      "----------\n",
      "train Loss: 2.3127 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 58/119\n",
      "----------\n",
      "train Loss: 2.3069 Acc: 0.1043\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 59/119\n",
      "----------\n",
      "train Loss: 2.3072 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 60/119\n",
      "----------\n",
      "train Loss: 2.3088 Acc: 0.1043\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 61/119\n",
      "----------\n",
      "train Loss: 2.3089 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 62/119\n",
      "----------\n",
      "train Loss: 2.3075 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 63/119\n",
      "----------\n",
      "train Loss: 2.3108 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 64/119\n",
      "----------\n",
      "train Loss: 2.3073 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 65/119\n",
      "----------\n",
      "train Loss: 2.3067 Acc: 0.1052\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 66/119\n",
      "----------\n",
      "train Loss: 2.3081 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 67/119\n",
      "----------\n",
      "train Loss: 2.3079 Acc: 0.1052\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 68/119\n",
      "----------\n",
      "train Loss: 2.3088 Acc: 0.1061\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 69/119\n",
      "----------\n",
      "train Loss: 2.3090 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 70/119\n",
      "----------\n",
      "train Loss: 2.3090 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 71/119\n",
      "----------\n",
      "train Loss: 2.3094 Acc: 0.1015\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 72/119\n",
      "----------\n",
      "train Loss: 2.3088 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 73/119\n",
      "----------\n",
      "train Loss: 2.3076 Acc: 0.1024\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 74/119\n",
      "----------\n",
      "train Loss: 2.3083 Acc: 0.1052\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 75/119\n",
      "----------\n",
      "train Loss: 2.3064 Acc: 0.1015\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 76/119\n",
      "----------\n",
      "train Loss: 2.3093 Acc: 0.1034\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 77/119\n",
      "----------\n",
      "train Loss: 2.3067 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 78/119\n",
      "----------\n",
      "train Loss: 2.3039 Acc: 0.1043\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 79/119\n",
      "----------\n",
      "train Loss: 2.3098 Acc: 0.1034\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 80/119\n",
      "----------\n",
      "train Loss: 2.3086 Acc: 0.1052\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 81/119\n",
      "----------\n",
      "train Loss: 2.3099 Acc: 0.1034\n",
      "val Loss: 2.2566 Acc: 0.2206\n",
      "\n",
      "Epoch 82/119\n",
      "----------\n",
      "train Loss: 2.3098 Acc: 0.1015\n",
      "val Loss: 2.2560 Acc: 0.2206\n",
      "\n",
      "Epoch 83/119\n",
      "----------\n",
      "train Loss: 2.3111 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 84/119\n",
      "----------\n",
      "train Loss: 2.3091 Acc: 0.1024\n",
      "val Loss: 2.2561 Acc: 0.2206\n",
      "\n",
      "Epoch 85/119\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1696:\n",
      "Process Process-1697:\n",
      "Process Process-1698:\n",
      "Process Process-1695:\n",
      "Process Process-1694:\n",
      "Process Process-1693:\n",
      "Process Process-1700:\n",
      "Process Process-1699:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 15396) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a383938eb6f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5d26eb52cfad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-9a383938eb6f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 15396) exited unexpectedly with exit code 1."
     ]
    }
   ],
   "source": [
    "sm, hist = train_model(sm, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def avgmodel(m, inp):\n",
    "    mn = torch.stack([m(inp[i].to(device)) for i in range(len(inp))]).squeeze().mean(0)\n",
    "    if len(mn.shape) == 1: return mn.max(0)[1]\n",
    "    return mn.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2475, -0.4040, -0.5777, -0.0768,  0.0328,  0.4112,  0.7051,\n",
      "          0.2025,  1.3419, -0.9156],\n",
      "        [ 0.1969,  0.5837, -0.0008,  0.5255,  0.1755, -0.2451,  1.1130,\n",
      "         -0.7582,  0.0414, -0.3068]], device='cuda:0')\n",
      "torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  6], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloaders['train']))\n",
    "mn = torch.stack([m(x[i].to(device)) for i in range(len(x))]).squeeze().mean(0)\n",
    "print(mn)\n",
    "print(mn.shape)\n",
    "mn.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.5748962905000057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f43201f86d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4321af64a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "Y = []\n",
    "for x,y in nt_dataloader:\n",
    "    prs = avgmodel(m,x)\n",
    "#     prs = sm(x)[len(x)-1,:,:].max(1)[1]\n",
    "    preds +=list(prs)\n",
    "    Y += list(y)\n",
    "scor = metrics.accuracy_score(Y, preds)\n",
    "print( scor )\n",
    "print(metrics.f1_score(Y,preds, average=\"weighted\"))\n",
    "plt.matshow(metrics.confusion_matrix(Y,preds).astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.5748962905000057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f432017e0f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4321a1c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scor = metrics.accuracy_score(Y, preds)\n",
    "print( scor )\n",
    "print(metrics.f1_score(Y,preds, average=\"weighted\"))\n",
    "plt.matshow(metrics.confusion_matrix(Y,preds).astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0395,  0.1186,  0.2006,  0.0897,  0.0829,  0.0907,  0.0668,\n",
       "           0.0928,  0.1574,  0.0610],\n",
       "         [ 0.0296,  0.1044,  0.4025,  0.0485,  0.0662,  0.0468,  0.0407,\n",
       "           0.0692,  0.1449,  0.0471]],\n",
       "\n",
       "        [[ 0.0172,  0.0475,  0.5648,  0.0503,  0.0398,  0.0293,  0.0723,\n",
       "           0.0562,  0.0728,  0.0498],\n",
       "         [ 0.0143,  0.0660,  0.3085,  0.0573,  0.0603,  0.0474,  0.0964,\n",
       "           0.0531,  0.1701,  0.1265]],\n",
       "\n",
       "        [[ 0.0193,  0.0432,  0.3705,  0.0484,  0.1606,  0.0406,  0.0742,\n",
       "           0.0473,  0.1235,  0.0724],\n",
       "         [ 0.0069,  0.0686,  0.5940,  0.0305,  0.0597,  0.0289,  0.0387,\n",
       "           0.0354,  0.1119,  0.0253]],\n",
       "\n",
       "        [[ 0.0192,  0.0687,  0.4567,  0.0727,  0.0475,  0.0289,  0.0297,\n",
       "           0.0693,  0.1643,  0.0430],\n",
       "         [ 0.0101,  0.0444,  0.6012,  0.0382,  0.0645,  0.0278,  0.0256,\n",
       "           0.0537,  0.0962,  0.0383]],\n",
       "\n",
       "        [[ 0.0402,  0.0892,  0.2531,  0.0645,  0.0485,  0.0333,  0.0593,\n",
       "           0.0697,  0.1940,  0.1483],\n",
       "         [ 0.0302,  0.0646,  0.2240,  0.0562,  0.1815,  0.0310,  0.0865,\n",
       "           0.0378,  0.1578,  0.1305]],\n",
       "\n",
       "        [[ 0.0183,  0.0693,  0.3903,  0.0238,  0.1662,  0.0367,  0.0556,\n",
       "           0.0421,  0.1378,  0.0598],\n",
       "         [ 0.0474,  0.0406,  0.3815,  0.0506,  0.1805,  0.0209,  0.0468,\n",
       "           0.0539,  0.1271,  0.0505]],\n",
       "\n",
       "        [[ 0.0163,  0.0572,  0.5570,  0.0442,  0.0403,  0.0563,  0.0291,\n",
       "           0.0754,  0.0710,  0.0531],\n",
       "         [ 0.0192,  0.0838,  0.2733,  0.1035,  0.0723,  0.0684,  0.0894,\n",
       "           0.0690,  0.1297,  0.0913]],\n",
       "\n",
       "        [[ 0.0150,  0.0399,  0.6344,  0.0413,  0.0446,  0.0195,  0.0223,\n",
       "           0.0503,  0.0857,  0.0470],\n",
       "         [ 0.0147,  0.0341,  0.5691,  0.0312,  0.0617,  0.0238,  0.0566,\n",
       "           0.0446,  0.0654,  0.0987]],\n",
       "\n",
       "        [[ 0.0229,  0.0479,  0.2622,  0.0625,  0.1311,  0.0307,  0.1312,\n",
       "           0.0503,  0.1526,  0.1085],\n",
       "         [ 0.0238,  0.0648,  0.3103,  0.0619,  0.1868,  0.0311,  0.1047,\n",
       "           0.0437,  0.1105,  0.0625]],\n",
       "\n",
       "        [[ 0.0211,  0.0502,  0.5113,  0.0336,  0.0720,  0.0219,  0.0385,\n",
       "           0.0537,  0.0786,  0.1189],\n",
       "         [ 0.0157,  0.0288,  0.5235,  0.0488,  0.0718,  0.0211,  0.0466,\n",
       "           0.0479,  0.1387,  0.0571]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f43201bbd30>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f432015d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([b for a,b in hist[\"val\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
