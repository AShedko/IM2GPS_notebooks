{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "from torchvision.datasets.folder import *\n",
    "import PIL, gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from itertools import chain\n",
    "import pretrainedmodels.utils as utils\n",
    "import pretrainedmodels\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "BATCH = 1\n",
    "N_layers = 2 # LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     23
    ]
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Special class\n",
    "class MultiImageFolder(data.Dataset):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, len_seq=4):\n",
    "        classes, class_to_idx = find_classes(root)\n",
    "        imgs = make_dataset(root, class_to_idx, [\".jpg\",\".jpeg\",\".png\"])\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.len_seq =len_seq\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)//self.len_seq\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        img_l = []\n",
    "        target_l = []\n",
    "        for i in range(self.len_seq):\n",
    "            path, target = self.imgs[self.len_seq*index+i]\n",
    "            img = self.loader(path)\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "            if target_l and target != target_l[0]: break\n",
    "            img_l += [img]\n",
    "            target_l += [target]\n",
    "\n",
    "        return img_l, target\n",
    "\n",
    "# Datasets\n",
    "data_dir = './LittlePlaNet/data/cities/'\n",
    "image_datasets = {x: MultiImageFolder(os.path.join(data_dir, x),\n",
    "                                           data_transforms[x], len_seq=8)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH,\n",
    "                                           shuffle=True, num_workers=8, drop_last=True)\n",
    "                   for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    hist = {\"train\":[], \"val\":[]}\n",
    "        \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':            \n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "                \n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "#                 inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                                            # last batch classes\n",
    "                    outputs = model(inputs)                                                \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    labels,\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * BATCH\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            hist[phase] += [[epoch_loss, epoch_acc]]\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = torch.load(\"models/resnet50_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, ms, out_dim):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.ms = ms\n",
    "#         self.trf = trf\n",
    "        self.out_dim = out_dim\n",
    "        self.lin  = [nn.Linear(out_dim,out_dim).to(device) for i in range(len(ms))]\n",
    "        for l in self.lin:\n",
    "            l.weight = torch.nn.Parameter(torch.ones(out_dim,out_dim, device=device))\n",
    "            l.bias = torch.nn.Parameter(torch.zeros(out_dim, device=device))\n",
    "        self.k  = len(ms)\n",
    "        \n",
    "    def forward(self, Xs):\n",
    "        #                     batch , out \n",
    "        res = torch.zeros(Xs[0].size(0), self.out_dim, requires_grad=True).to(device)\n",
    "        for i in  range(len(Xs)):\n",
    "            res +=  self.lin[i%self.k](self.ms[i%self.k](Xs[i].to(device)))\n",
    "        res = nn.Softmax(dim=1)(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgmodel(m, inp):\n",
    "    mn = torch.stack([m(inp[i].to(device)) for i in range(len(inp))]).squeeze().mean(0)\n",
    "    if len(mn.shape) == 1: return mn.max(0)[1]\n",
    "    return mn.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trf = nn.Sequential(*list(model_ft.children())[:-3])\n",
    "# md  = nn.Sequential(*list(model_ft.children())[-3:])\n",
    "ens = Ensemble([ model_ft for i in range(3)], 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam( chain([list(ens.lin[i].parameters())[0] for i in range(3)],\n",
    "                                 [list(ens.lin[i].parameters())[1] for i in range(3)]), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.2547 Acc: 0.3676\n",
      "val Loss: 2.1996 Acc: 0.4167\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.1368 Acc: 0.5294\n",
      "val Loss: 2.1735 Acc: 0.5417\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.0734 Acc: 0.5637\n",
      "val Loss: 2.0904 Acc: 0.3333\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.0176 Acc: 0.6373\n",
      "val Loss: 2.0061 Acc: 0.6667\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.9416 Acc: 0.7010\n",
      "val Loss: 2.0049 Acc: 0.5417\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.9067 Acc: 0.7647\n",
      "val Loss: 1.9575 Acc: 0.5417\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.9023 Acc: 0.7255\n",
      "val Loss: 1.8947 Acc: 0.6667\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.8695 Acc: 0.7549\n",
      "val Loss: 1.9473 Acc: 0.5417\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 1.8378 Acc: 0.8137\n",
      "val Loss: 1.9824 Acc: 0.5000\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.8566 Acc: 0.7941\n",
      "val Loss: 1.9733 Acc: 0.5833\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.8536 Acc: 0.7598\n",
      "val Loss: 1.9781 Acc: 0.5417\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.8792 Acc: 0.7647\n",
      "val Loss: 1.9216 Acc: 0.7083\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.8461 Acc: 0.7647\n",
      "val Loss: 1.9992 Acc: 0.5833\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.8305 Acc: 0.8186\n",
      "val Loss: 2.0739 Acc: 0.5000\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.8302 Acc: 0.8137\n",
      "val Loss: 1.9600 Acc: 0.5417\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.8212 Acc: 0.7941\n",
      "val Loss: 1.9769 Acc: 0.5000\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.8369 Acc: 0.7696\n",
      "val Loss: 1.9300 Acc: 0.6667\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.8680 Acc: 0.7451\n",
      "val Loss: 1.9601 Acc: 0.5833\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.8572 Acc: 0.7451\n",
      "val Loss: 1.8800 Acc: 0.6667\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.8559 Acc: 0.7647\n",
      "val Loss: 1.9356 Acc: 0.6667\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.8419 Acc: 0.7500\n",
      "val Loss: 1.9694 Acc: 0.5417\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 1.8446 Acc: 0.7941\n",
      "val Loss: 1.9773 Acc: 0.5833\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 1.8298 Acc: 0.8137\n",
      "val Loss: 1.9264 Acc: 0.5833\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 1.8247 Acc: 0.7941\n",
      "val Loss: 2.0644 Acc: 0.3750\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 1.8041 Acc: 0.8333\n",
      "val Loss: 1.9570 Acc: 0.5000\n",
      "\n",
      "Training complete in 27m 33s\n",
      "Best val Acc: 0.708333\n"
     ]
    }
   ],
   "source": [
    "ens, hist = train_model(ens,criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestds = MultiImageFolder(\"data/cities/\",data_transforms[\"test\"],len_seq=5)\n",
    "nt_dataloader = torch.utils.data.DataLoader(\n",
    "    newtestds,batch_size=BATCH, shuffle=True, num_workers=4, drop_last=True)\n",
    "class_names = newtestds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = torch.load(\"models/ens_trained\")\n",
    "# ens.ms = [m.cpu() for m in ens.ms ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5d172b6dc224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavgmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     prs = sm(x)[len(x)-1,:,:].max(1)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# map will interleave them.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration over a 0-d tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "#avg\n",
    "preds = []\n",
    "Y = []\n",
    "for x,y in nt_dataloader:\n",
    "    prs = avgmodel(model_ft,x)\n",
    "#     prs = sm(x)[len(x)-1,:,:].max(1)[1]\n",
    "    preds +=list(prs.cpu())\n",
    "    Y += list(y.cpu())\n",
    "scor = metrics.accuracy_score(Y, preds)\n",
    "print( scor )\n",
    "print(metrics.f1_score(Y,preds, average=\"weighted\"))\n",
    "plt.matshow(metrics.confusion_matrix(Y,preds).astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635\n",
      "0.6377454501632739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcdf017dd68>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcdf08a5710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "Y = []\n",
    "for x,y in nt_dataloader:\n",
    "#     x = [xi.cpu() for xi in x]\n",
    "    _, prs = ens(x).max(1)\n",
    "    preds +=[prs.cpu()]\n",
    "    Y +=[y.cpu()]\n",
    "scor = metrics.accuracy_score(Y, preds)\n",
    "print( scor )\n",
    "print(metrics.f1_score(Y,preds, average=\"weighted\"))\n",
    "plt.matshow(metrics.confusion_matrix(Y,preds).astype(np.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Ensemble. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(ens,\"models/ens_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "# hist= hist_new\n",
    "train = np.asarray(hist[\"train\"])\n",
    "val = np.asarray(hist[\"val\"])\n",
    "plt.plot(range(25),train[:,0], label = \"Train\")\n",
    "plt.plot(range(25),val[:,0], label = \"Val\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# plt.yticks(np.arange(1.3,2.3, step=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fcdf0830400>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ashedko/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(dataloaders[\"val\"]))\n",
    "# x = x\n",
    "# r = ens(x)\n",
    "# x[1].shape\n",
    "prs = avgmodel(model_ft,x)\n",
    "prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Num examples')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce500e2b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "x=[2,5,8,10]\n",
    "y1=[0.502,0.635,0.656,0.74]\n",
    "y2=[0.504,0.637,0.633,0.741]\n",
    "\n",
    "plt.plot(x,y1, label=\"ACC\")\n",
    "plt.plot(x,y2, label=\"F1\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Num examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
